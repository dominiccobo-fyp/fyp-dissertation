\chapter{Iterations}

\section{Establishing the Architectural Plumbing}

There are two choices when it comes to creating modular applications, either a plugin based system, such as Javaâ€™s OSGi standard, or independent applications that communicate over some form of local or remote connection.

Naturally, this poses questions as to what the nature of scale of the problem would be; in our case, tying multiple information sources together, typical of a medium size corporation do we lean to the solution that better applies to a larger scale.

Extensibility in our case is important; there is an inexorable need for addition of new sources. Plugins are the inherent approach to providing modular extension to a monolithic architecture (Figure \ref{fig:monolithic-approach}). Whereas, as a superset of Service Oriented Architecture, Micro-services are more strongly decoupled (Figure \ref{fig:distributed-approach}), relying on middleware to communicate based on some form of predefined contract.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{monolithic-approach.png}
	\caption{Component Diagram Illustrating Monolithic Approach}
	\label{fig:monolithic-approach}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{distributed-application.png}
	\caption{Component Diagram Illustrating Distributed Approach}
	\label{fig:distributed-approach}
\end{figure}

With large amounts of data exchanged - as is the potential in the envisioned system - a single monolithic application acting as the single processor of the data can rapidly become the chokepoint, subject to temporary mediation via vertical scaling. In contrast, these problems are easily mitigated in distributed architecture through horizontal scaling.

Microservices are no silver bullet approach to proverbial modularity and, or business scalability. In fact, they are often associated with greater development overhead, especially, in the aspect of integration and testing due to lack of immediate feedback on changes; the appropriation of the correct culture, practises and tooling can mitigate many of these overheads. Failing these appropriations, other common anti patterns may emerge, such as distributed monoliths. We will discuss these later.

There are many integration patterns for distributed systems. EIP - a referential principle-driven manual - notes their shortcomings and benefits, but strongly recommends messaging integration patterns as the best approach for most Enterprise problems favouring them based on their high frequency, asynchronous capability.

Implementing a fully functional, distributed messaging solution is complex endeavour; reinventing the wheel is futile when there are ample choices to choose from; RabbitMQ, Apache Kafka, to name a few. Not withstanding the reduction of unnecessary development effort, from the elimination of implementing middleware, duct tape code is still necessary to handle the endpoints connecting to these.

The JVM and its associated languages, are ubiquitous in back office systems in many businesses across the globe; this maturity yields stage to many out-of-the-box solutions to common enterprise problems such as that which we have discussed. Spring is an example of one of the most widely adopted enterprise Java frameworks facilitating these aids.

Spring itself does not however dictate the style of distributed programming but offers a strongly opinionated view on the approaches available. We chose the Command Query Responsibility Segregation (CQRS) approach based on its focus on separation of updating a set of projections - query models - and updating of a central decoupled model - command models. Implementing this pattern is infamously difficult, but with help of an extension based on Spring - Axon Framework - can we reduce much of this effort.  

With the choice of Axon come some beneficial consequences. The framework provides a strongly opinionated view of what is best for the developer; its strong point lays in its approach to Messaging. It defines its own Message Bus implementation - which can be substituted from a set of other choices if needed - as well as handling all of the boiler-plating that would otherwise be needed to glue message endpoint consumption together.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{distributed-approach-with-axon.png}
	\caption{Component Diagram Illustrating Axon Approach}
	\label{fig:distributed-approach}
\end{figure}

\section{Establishing a Retrieval Mechanism}

Having established, through thorough evaluation, a sound architecture, we proceed to establishing our approach to how data is expected to flow between the defined components. Having defined, and implemented a rough architecture above, we resort to implementing a minimum viable product for retrieving from a client for which we choose a HTTP Web Approach with a single test parameter in the pursuit of a creation of query handler that will return a basic hello world message returning the test parameter appended. Following this approach, we are able to create a very simple test case to verify the functionality (Figure \ref{fig:e2eMockTest}).

\begin{figure}[h!]
		\centering
		\lstinputlisting[language=Python, showspaces=false,                
		showstringspaces=false, tabsize=2]{e2e-acceptance-test-1.py}
		\caption{End To End Test for Mock Example}
		\label{fig:e2eMockTest}
\end{figure}

To achieve the functionality, we define a query object capable of transmitting the test payload. The query object also serves as the contract for those wishing the act on it based on its object signature. We model this process in Figure. Clients receive a query through an interface which they dispatch with context to the message bus and which is then returned from the appropriate source. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{first_e2e_test_class_uml.png}
	\caption{UML Class Diagram of the models involved in building and responding to a query}
	\label{fig:firste2etestclassuml}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{process-diagram.png}
	\caption{Process diagram illustrating flow of query from its handling to response}
	\label{fig:processSequenceQueryFlow}
\end{figure}

By implementing this approach, we end up with a core code example of what will form the implementation pattern throughout this project (Figure \ref{fig:e2eMockClass}). The simplicity of this approach is evident and strongly contributes to our goal of ease of extensibility. The complexity of deploying this distributed application is handled through the use of containerisation - Docker - and container orchestration - Docker Compose. 

Despite not performing much processing, the response times indicate a positive approach to reducing the time taken to retrieve information.

% TODO: insert graph here.

% TODO: what are the response times like here?

\begin{figure}[h!]
	\centering
	\lstinputlisting[language=Java, showspaces=false,                
	showstringspaces=false, tabsize=2, breaklines=true]{mock-e2e.java}
	\caption{End To End Implementation for Mock Example}
	\label{fig:e2eMockClass}
\end{figure}

\section{Connecting an IDE - Evaluating the Push Model}

In the previous section, we successfully managed to establish a basic decoupled communication model that enabled the easy integration of information from a given source. In line with the background research, we have a key interest in reducing the amount of context switching between multiple sources performed by a developer and as found the IDE to be a suitable approach. We also explored the relevance of simple problems such as the Language Server Protocol. 

We now explore the extension of our current solution in pursuit of the ability to connect it to an IDE. In this case, Visual Studio Code.  

When thinking of creating reusable IDE Intelligence that can used to enrich context based on a given syntax and or grammar, we may consider the Language Server protocol. We may examine examples of its usage, such as Eclipse's Java LSP implementation, which uses the Eclipse Java Development Tools to provide Java support to all LSP supporting IDEs.

\begin{figure}[h!]
	
	\digraph[width=\textwidth]{eclipseLanguageServer}{rankdir=LR; 
		IDE->languageServer [label="Push Ctx"];
		languageServer->IDE [label="Send ctx info"];
		languageServer->eclipseJdt [label="Send File Ctx Info"]; 
		eclipseJdt->languageServer [label="Send java ctx info"];
		
		languageServer[label=<Language Server>];
		eclipseJdt[label=<Eclipse Java <br/> Development Toolkit>];
	}
	
	\caption{Eclipse's Java Language Server}
	
\end{figure}

We are not interested in providing Java Language completion suggestions, as is the example case; instead, our case focuses on providing context information, with this sprint requiring the ability to display mock implementation examples.

Replacing the ability to provide Java language suggestions as in the example with that of global context information, a way forward is visible.

\begin{figure}[h!]
	
	\digraph[width=\textwidth]{ctxResolverInfo}{rankdir=LR; 
		IDE->languageServer [label="Push Ctx"];
		languageServer->IDE [label="Send ctx info"];
		languageServer->ctxProvider [label="Extracted Ctx Info"]; 
		ctxProvider->languageServer [label="Resolved examples for ctx"];
		
		ctxProvider[label=<Context Provider>];
		languageServer[label=<Language Server>];
	}
	\caption{Using a language server as middleware to resolve context}
\end{figure}

\begin{figure}[h!]
    \centering
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=1\linewidth]{push_trial_story.png}
		\caption{User Story}
	\end{subfigure}
	\begin{subfigure}[t]{0.6\textwidth}
		\includegraphics[width=1\linewidth]{push-wireframe}
		\caption{Wireframe}
	\end{subfigure}
	\label{fig:mvpPush}
	\caption{Minimum Viable Product Illustration for Push Approach}
\end{figure}

After demonstrating the resulting product of this sprint, we note that this approach suffers from multiple shortcomings.

It is visibly computationally expensive to constantly react and respond to each IDE action to provide the necessary global context data. The latency taken to resolve this, running locally and with mocked data, suggests this approach as being non-viable. 

Assessing against at our aim, whilst we have managed to enrich a our local scope with global context within the IDE, demonstrating sound feasibility, the latency, creates a natural impediment to usage.

These learnings suggest the trial of an alternative approach: a command triggered pull-based model where the information is requested when needed.

\section{Connecting an IDE - Evaluating the Pull Model}

With the performance and usability issues experienced through the push approach, implementing the Language Server Protocol, we resort to trialling a pull model. This conserves the architectural style, but drops the implementation of a language protocol in favour of a more bare-bones request-reply HTTP service. 

\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=1\linewidth]{pull_trial_story.png}
		\caption{User Story}
	\end{subfigure}
	\begin{subfigure}[t]{0.6\textwidth}
		\includegraphics[width=1\linewidth]{pull-wireframe}
		\caption{Wireframe}
	\end{subfigure}
	\label{fig:mvpPull}
	\caption{Minimum Viable Product Illustration for Pull Approach}
\end{figure}

\section{Reflecting on IDE Extension Development}
We have mostly acted on a single, non-realistic, query payload for purpose of demonstration. 

% TODO: we now see the how context can be done.

Modelling a context object that would address every single need is difficult. Evolving an unstable API until we take into account the Pareto ratio of use cases, less so. 

Repository mining is often done with a Version Control System as a source. A natural choice given this is the point of integration of many other systems. Sharing the reference to individual projects in a VCS seems a viable starting  point. We chose Git, based on its dominance as the go-to VCS.

% TODO: ref needed. 

\begin{figure}[h!]
	{\centering
		\digraph{ctxObject} {	     
			Context [
			fontsize=8
			shape=none
			label = <
			<table cellborder="1" border="0" cellspacing="0">
			<tr><td>Context</td></tr>
			<tr><td>+ Git Context</td></tr>
			<tr><td>+ Document Context</td></tr>	     		
			</table>
			>
			];
			
			GitContext [
			fontsize=8
			shape=none
			label = <
			<table cellborder="1" border="0" cellspacing="0">
			<tr><td>Git Context</td></tr>
			<tr><td>+ Remote Name</td></tr>
			<tr><td>+ Remote URL</td></tr>	     		
			</table>
			>
			];
			
			DocumentContext [
			fontsize=8
			shape=none
			label = <
			<table cellborder="1" border="0" cellspacing="0">
			<tr><td>Document Context</td></tr>
			<tr><td>+ File URI</td></tr>  		
			</table>
			>
			];
			
		}
		\caption{Query Context Model}
	}
	
\end{figure}

Each IDE will naturally have a varying level of intelligence and many will be able to provide these attributes without any implementation effort required. One must consider the lowest common denominator in order to avoid any unnecessary normalising implementation of the same logic across each IDE; for example, the URI of an open file and folders, allowing the language server to bare the burden of enriching these to produce a context object. 

\begin{center}
	\begin{table}
		\begin{tabular}{|c| p{10cm} |}
			\hline 
			IDE & API Description \\ 
			\hline 
			JetBrains IntelliJ & \url{http://www.jetbrains.org/intellij/sdk/docs/welcome.html} \\ 
			\hline 
			VSCode & \url{https://code.visualstudio.com/api} \\ 
			\hline 
			Atom & \url{https://flight-manual.atom.io/api/v1.43.0/AtomEnvironment/} \\ 
			\hline 
			Eclipse & \url{https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.platform.doc.isv%2Freference%2Fapi%2Forg%2Feclipse%2Fcore%2Fruntime%2FPlugin.html} 
				\\
				\hline 
			\end{tabular} 
			\caption{Extension API for main RTEs / IDEs}
			\label{table:2}
		\end{table}
\end{center}

	
\section{Applying to Real Data - GitHub Work Items}

- Why is this the next step?

- What are work items?

- Why GitHub?

- What do we interpret as work items for Github?

- How do we do this?

- What are the alternative approaches to retrieving this data?

- Is this quicker than retrieving the work items manually?

\section{Applying to Real Data - GitLab Work Items}

- Why is this the next step?

- Why GitLab?

- What do we interpret as work items for GitLab?

- How do we do this?

- What are the alternative approaches to retrieving this data?

- Is this quicker than the alternative?

\section{Applying to Real Data - GitHub Experts}

- Why is this the next step?

- What are experts?

- Why GitHub?

- What do we interpret as experts in GitHub?

- What are the alternative approaches to retrieving this data?

- What are the improvements over the alternative?

\section{Addressing real world performance issues}

- Why is this the next step?

- What's the current performance

- How do we identify the choke points?

\section{Applying to Real Data - Stack Overflow Documentation}

- Why is this the next step?

- What is documentation

- Why Stack overflow

- What are the alternative approaches to retrieving this data.

- What are the improvements over this?

\section{Refining Presentation for Extensibility}

- Why this step next?

- What was wrong with the previous approach?

- What is the new approach?

- Does this new approach offer improvements?

%\input{iterations/sprint1.tex}
%\input{iterations/sprint2.tex}
%\input{iterations/sprint3.tex}
%\input{iterations/sprint4.tex}
%\input{iterations/sprint5.tex}
%\input{iterations/sprint6.tex}
%\input{iterations/sprint7.tex}
%\input{iterations/sprint8.tex}